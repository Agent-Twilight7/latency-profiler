# âš¡ Latency Profiler for REST APIs

> ğŸš€ A benchmarking suite to simulate and analyze REST endpoint latencies under load â€” designed with performance-critical applications like **high-frequency trading (HFT)** in mind.

---

## ğŸ“Œ What This Project Does

- Simulates a trading system backend with 3 REST endpoints (market data, order submission, trade ack).
- Measures round-trip latency with **nanosecond precision** using Pythonâ€™s `time.monotonic_ns()`.
- Provides CLI scripts + a **real-time Streamlit dashboard** for running tests.
- Visualizes latency spread using **box plots**, highlights outliers and jitter.
- Enables export of results to **CSV** for deeper analysis.

---

## ğŸ› ï¸ Tech Stack

- **Python 3**
- **Flask** (mock backend)
- **Requests** (benchmarking)
- **Pandas + Seaborn + Matplotlib** (data analysis + visualization)
- **Streamlit** (real-time dashboard)

---

## ğŸ¯ Simulated Endpoints

| Endpoint            | Component Simulated       | Latency Range |
|---------------------|---------------------------|----------------|
| `/market_data`      | Market data feed handler  | 5â€“15 ms       |
| `/order_submission` | Order router              | 20â€“35 ms      |
| `/trade_ack`        | Trade confirmation engine | 10â€“25 ms      |

---

## ğŸ“Š Core Features

### âœ… CLI Benchmarking Scripts
- `profiler.py`: Serial latency measurement
- `concurrent_profiler.py`: Multi-threaded load simulation
- `plot.py`: Visualizes data from either CSV

### âœ… Real-Time Streamlit Dashboard
- Select endpoint, threads, request count
- See live results and latency distributions
- Download result CSVs for logs or reports

![Screenshot of Streamlit](dashboard.png)
<img src="latency_plot_concurrent.png" width="550">


---

## ğŸ§  Why This Matters (Use Case)

This project demonstrates awareness of **latency as a first-class system concern** â€” essential in HFT, SRE, and low-latency backend development roles. It provides tooling to:
- Profile latency and jitter
- Detect spikes and outliers
- Simulate concurrent system load
- Visualize trends in response times

---

## ğŸ“ File Structure
```
latency-profiler/
â”œâ”€â”€ app.py                        # Flask mock server
â”œâ”€â”€ profiler.py                   # Serial benchmark
â”œâ”€â”€ concurrent_profiler.py        # Threaded concurrency test
â”œâ”€â”€ plot.py                       # Data visualization
â”œâ”€â”€ dashboard.py                  # Streamlit UI
â”œâ”€â”€ latency_log.csv               # Serial output
â”œâ”€â”€ concurrent_latency_log.csv    # Concurrent output
â”œâ”€â”€ latency_plot.png              # Plot (serial)
â”œâ”€â”€ latency_plot_concurrent.png   # Plot (concurrent)
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # Docs
```
---

## ğŸ“¥ Getting Started

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Start the mock API server
python app.py

# 3. Run benchmark (choose one):
python profiler.py
python concurrent_profiler.py

# 4. Plot the results
python plot.py

# 5. Or launch the dashboard UI
streamlit run dashboard.py
